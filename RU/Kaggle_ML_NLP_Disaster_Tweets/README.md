# Проект Определение фэйковых и реальных твитов про катастрофы
> Тестовое задание Kaggle, на основе истории твитов обучить модель, которая будет предсказывать реальный твит про катастрофу или фейк.

## Содержание
* [Цель](#Цель)
* [Последовательность действий](#Последовательность-действий)
* [Использованные библиотеки](#Использованные-библиотеки)
* [Итоговый результат](#Итоговый-результат)
* [Вывод](#Вывод)

## Цель
**Обучить модель для определения реальных твитов и фейков**

## Последовательность действий
- твиты очищены от дополнительных символов, стоп-слов
- проведена лемматизация
- сделан анализ популярных слов отдельно для твитов о реальных катастрофах и фейковых
- обучены 4 модели с параметрами по умолчанию и подбором гиперпараметров

## Использованные библиотеки
- Модели: CatBoost, LightGBM, LinearRegression, Random Forrest, для подбора параметров использовался GridSearchCV
- matplotlib, sklearn, torch, nltk, CountVectorizer, TfidfVectorizer, pymystem3


## Итоговый результат
| Model                | Test f1 score |
|----------------------|---------------|
| LGBM_model_grid      | 0.743854      |
| LGBM_model           | 0.743187      |
| model_catboost_cv    | 0.756369      |
| model_catboost       | 0.752602      |
| DecisionTree         | 0.692712      |
| DecisionTree_grid    | 0.62723       |
| LogicRegression      | 0.761194      |
| LogicRegression_grid | 0.768182      |

## Вывод
Лучшая модель на тестовой выборке LogicRegression 0.7981
